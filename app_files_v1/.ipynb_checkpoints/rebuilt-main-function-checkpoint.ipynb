{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import unittest\n",
    "import random\n",
    "from time import sleep\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from pandas.io.sql import SQLTable\n",
    "#import webscrape_pd_scrape_patheos as pscrape\n",
    "import sys\n",
    "#import database_insert_oracle as oracledb\n",
    "#from passlib.hash import pbkdf2_sha256\n",
    "try:\n",
    "    from configparser import ConfigParser\n",
    "    from configparser import SafeConfigParser\n",
    "except ImportError:\n",
    "    from ConfigParser import ConfigParser  # ver. < 3.0\n",
    "    from ConfigParser import SafeConfigParser\n",
    "    \n",
    "HEADERS = {'user-agent': ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)'\n",
    "                          'AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "                          'Chrome/73.0.3683.114 Safari/537.36'),\n",
    "                          'referer': 'https://www.patheos.com/blogs/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_system_status_values(file, section, option, value):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    cfgfile = open(file, 'w')\n",
    "    if config.has_section(section) == True:\n",
    "        config.set(section, option, value)\n",
    "    else:\n",
    "        config.add_section(section)\n",
    "        config.set(section, option, value)\n",
    "    config.write(cfgfile)\n",
    "    cfgfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_config_file(file, section, option):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    if config.has_option(section, option) == True:\n",
    "        page_number = int(config.get(section, option))\n",
    "    else:\n",
    "        page_number = 1\n",
    "    return page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_config_file(file):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    return_save = []\n",
    "    if config.has_option('SAVE POINT', 'Category') == True:\n",
    "        category = config.get('SAVE POINT', 'Category')\n",
    "        return_save.append(category)\n",
    "    else:\n",
    "        category = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Blog') == True:\n",
    "        blog = config.get('SAVE POINT', 'Blog')\n",
    "        return_save.append(blog)\n",
    "    else:\n",
    "        blog = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Blog-Key') == True:\n",
    "        blog_key = config.get('SAVE POINT', 'Blog-Key')\n",
    "        return_save.append(blog_key)\n",
    "    else:\n",
    "        blog_key = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Page') == True:\n",
    "        page = int(config.get('SAVE POINT', 'Page'))\n",
    "        return_save.append(page)\n",
    "    else:\n",
    "        page = 0\n",
    "           # list contains: [category, blog, blog_key, page]\n",
    "    return return_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patheos_urls_from_page(url, index=None):\n",
    "    url_test = requests.get(url)\n",
    "    if url_test != \"<Response [404]>\":\n",
    "        soup2 = BS(url_test.content, 'html.parser')\n",
    "        if index == None:\n",
    "            post_urls = []\n",
    "            for blog[0] in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                blog_url1 = blog.find('a')\n",
    "                blog_url2 = blog_url1['href']\n",
    "                post_urls.append(blog_url2)\n",
    "        else:\n",
    "            for blog[int(index)] in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                blog_url1 = blog.find('a')\n",
    "                blog_url2 = blog_url1['href']\n",
    "                post_urls = blog_url2\n",
    "    else:\n",
    "        if index == None:\n",
    "            post_urls = []\n",
    "        else:\n",
    "            post_urls = ''\n",
    "    return post_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_blogs():\n",
    "    url = 'http://www.patheos.com/blogs'\n",
    "    response = requests.get(url)\n",
    "    soup = BS(response.content, 'html.parser')\n",
    "\n",
    "    blog_list = []\n",
    "\n",
    "    for blog in soup.find_all('div', attrs={\"class\":\"related-content clearfix related-content-sm decorated channel-list\"}):\n",
    "        blog_url1 = blog.find('a')\n",
    "        blog_url2 = blog_url1['href']\n",
    "        blog_list.append(blog_url2) \n",
    "\n",
    "    blog_lists = []\n",
    "    \n",
    "    for i in blog_list:\n",
    "        split_url = i.rsplit(\"/\")\n",
    "        blog_name = split_url[3]\n",
    "        blog_lists.append(blog_name)\n",
    "    \n",
    "    #df_blog_dict = pd.DataFrame()\n",
    "    \n",
    "    blog_dict = {i:[] for i in blog_lists}\n",
    "\n",
    "    blog_cat_prefix = \"https://www.patheos.com/\"\n",
    "\n",
    "    i = 0    \n",
    "    for blog_urls in tqdm(blog_dict, desc='Fetch blog urls for each category'):\n",
    "        if blog_urls:\n",
    "            query_url = blog_cat_prefix + blog_urls\n",
    "            #sleep(random.uniform(1, 3))\n",
    "            subsub_blog = requests.get(query_url)\n",
    "            soup2 = BS(subsub_blog.content, 'html.parser')\n",
    "            for blog in soup2.find_all('div', attrs={\"class\":\"author-info\"}):\n",
    "                for blog_url0 in blog.find_all('div', attrs={\"class\":\"title\"}):\n",
    "                    blog_url1 = blog_url0.find('a')\n",
    "                    blog_url2 = blog_url1['href']\n",
    "                    blog_dict[blog_urls].append(blog_url2)\n",
    "\n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    #df_blog_dict.to_csv('category_blogurls.csv')\n",
    "    return blog_dict\n",
    "    #return df_blog_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_blog_dict(blog_dict, sql_connections):\n",
    "    df_results = pd.DataFrame(columns=('pk','category','blog_url'))\n",
    "    df_results.set_index('pk')\n",
    "    for c in blog_dict:\n",
    "        for b in tqdm(c, desc='Fetching primary keys for blogs'):\n",
    "            g_category = c\n",
    "            g_blog_url = b\n",
    "            blog_pk = oracledb.find_blog_pk(b, sql_connections)\n",
    "            if g_category and g_blog_url is not None:\n",
    "                if blog_pk != -1:\n",
    "                    df_temp = pd.DataFrame([[g_blog_pk.text,      # blog db pk\n",
    "                                             g_category.text,     # blog name\n",
    "                                             g_blog_url.text]]    # blog url\n",
    "                                            columns=('pk','category','blog_url'))\n",
    "                    df_results = df_results.append(df_temp)\n",
    "                else:\n",
    "                    df_hold = pd.DataFrame([[g_category.text,\n",
    "                                             g_blog_url.text]]\n",
    "                                            columns=('category','blog_url'))\n",
    "    # I'm banking on this adding the new entries to the bottom of the list and \n",
    "    # adding index numbers that are higher than the rest of the entries. These are\n",
    "    # not what the pk for these will end up being, but they will allow them to sit\n",
    "    # further down on the list than the save point location (i.e., they won't get missed)\n",
    "    df_results = df_results.append(df_hold, ignore_index=True)\n",
    "    return df_results\n",
    "        \n",
    "        \n",
    "# blog_dict structure:\n",
    "#  - dictionary name: blog_dict\n",
    "#  - key names: category\n",
    "#  - values: list of all category blog urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_404(blog, page_number, increment, name):\n",
    "    pn = 0\n",
    "    return_str = page_number\n",
    "    continue_on = True\n",
    "    if page_number < 1:\n",
    "        pn = increment\n",
    "        return_str = 0\n",
    "    else:\n",
    "        pn = page_number + increment    \n",
    "    blog_test = requests.get(blog, timeout=5)\n",
    "    blog_url = blog_test.url\n",
    "    while continue_on == True:\n",
    "        blog_page_url = blog_url + \"page/\" + str(pn)\n",
    "        if pn < 20000:\n",
    "            try:\n",
    "                url_test = requests.get(blog_page_url, timeout=5) #, allow_redirects=True)\n",
    "                #sleep(random.uniform(1, 3))\n",
    "                if url_test.status_code != 404:\n",
    "                    sys.stdout.write('\\r' + blog + \" | page(\" + str(pn) + \")\") # | category total: (\" + str(t) + \")\")\n",
    "                    return_str = pn\n",
    "                    pn = pn + increment\n",
    "                else:\n",
    "                    continue_on = False                \n",
    "            except:\n",
    "                return_str = -1\n",
    "                continue_on = False\n",
    "        else:\n",
    "            return_str = -2\n",
    "            continue_on = False\n",
    "    if increment == 1:\n",
    "        sys.stdout.write('\\r' + blog + \" | page(\" + str(return_str) + \")\") # | category total: (\" + str(t) + \")\")        \n",
    "    return return_str                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_find_pages(blogname_list, list_name):\n",
    "    c = 0\n",
    "    t = 1\n",
    "    b = 1\n",
    "    url_list = []\n",
    "    continue_on = True\n",
    "    #for i in blogname_list:\n",
    "    #    if i != \"\":\n",
    "    i = blogname_list\n",
    "    try:\n",
    "        continue_on = True\n",
    "        page_prefix = \"/page/\"\n",
    "        blog_name = i.rsplit(\"/\")\n",
    "        try:\n",
    "            p = int(exists_config_file('patheos_blogs_pages.ini', list_name, blog_name[4]))\n",
    "        except:\n",
    "            continue\n",
    "        if not p:\n",
    "            p = 0\n",
    "        try:\n",
    "            p1 = test_404(i, p, 500, blog_name[4])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if ((p1 != -1) and (p1 != -2)):\n",
    "            p2 = test_404(i, p1, 100, blog_name[4])\n",
    "            p = p1\n",
    "            if p2 != -1:\n",
    "                p3 = test_404(i, p2, 50, blog_name[4])\n",
    "                p = p2\n",
    "                if p3 != -1:\n",
    "                    p4 = test_404(i, p3, 25, blog_name[4])\n",
    "                    p = p4\n",
    "\n",
    "        if ((p != -1) and (p != -2)):\n",
    "            while continue_on == True:    \n",
    "                sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "                p = test_404(i, p, 1, blog_name[4])\n",
    "                continue_on = False\n",
    "            t = t + p\n",
    "            b = b + 1\n",
    "            update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "        else:\n",
    "            update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "            b = b + 1\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "    except:\n",
    "        p = -1\n",
    "        update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "        sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "#else:\n",
    "#    update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "#    sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "\n",
    "fail_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetch blog urls for each category: 100%|██████████| 20/20 [00:06<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def pass_dict_list(blog_dict, file):\n",
    "    df_lists_results = pd.DataFrame()\n",
    "    \n",
    "    blog_posts = {i:[] for i in blog_dict}\n",
    "    for i in blog_dict:\n",
    "        #result_list = fetch_page_posts(i, blog_dict[i], file)\n",
    "        result_list = fetch_page_posts(i, blog_dict[i], file)\n",
    "        blog_posts[i].append(result_list)\n",
    "    return blog_posts #dictionary\n",
    "\n",
    "def fetch_page_posts(blog_dict, file, connection_info): #(dictionary, string, list)\n",
    "#def fetch_page_posts(list_name, pages_url_list, file):\n",
    "    p = 1\n",
    "    url_list = []\n",
    "    continue_on = True\n",
    "    page_prefix = \"page/\"\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    # db_user = connection_info[0]\n",
    "    # db_password = connection_info[1]\n",
    "    # user = connection_info[2]\n",
    "    # database = connection_info[3]\n",
    "    sql_connectsions = oracledb.database_connect_oracle(db_user, db_password, user, database)\n",
    "    ############\n",
    "    input_df = convert_blog_dict(blog_dict, sql_connections)\n",
    "    \n",
    "    # RESTORE SAVE POINT PROCESS\n",
    "    save_point_list = save_point_config_file('patheos_save_point.ini')\n",
    "    if save_point_list[2] != 0:\n",
    "        save_category = save_point_list[0]\n",
    "        save_blog = save_point_list[1]\n",
    "        save_key = save_point_list[2]\n",
    "        save_page = save_point_list[3]\n",
    "    else:\n",
    "        save_page = 1\n",
    "        \n",
    "        # TEST SAVE POINT PAGE\n",
    "        #top_url = get_patheos_urls_from_page(save_page, 0)\n",
    "        #status_code = oracledb.database_post_compare(top_url, sql_connections)\n",
    "        #if status_code == 1: # found in database\n",
    "        #        \n",
    "        #    # TEST NEXT PAGE UNTIL SUCCESSUL\n",
    "        #    test_page = save_page\n",
    "        #    while status_code == 1:\n",
    "        #        test_page = test_page + 1\n",
    "        #        top_url = get_patheos_urls_from_page(test_page, 0)\n",
    "        #        status_code = oracledb.database_post_compare(top_url, sql_connections)\n",
    "        #    if status_code == 0: # not found in database\n",
    "        #        adjusted_save = test_page - 1\n",
    "        #else:\n",
    "        #    adjusted_save = save_page\n",
    "        \n",
    "    for i, row in islice(input_df.itertuples(), save_key, None):\n",
    "        blog_find_pages(row.blog_url, row.category)\n",
    "        blog_name = row.blog_url.rsplit(\"/\")\n",
    "        pages = save_page\n",
    "        blog_test = requests.get(e, timeout=5)\n",
    "        blog_url = blog_test.url\n",
    "        tposts = 0\n",
    "        pull_page = save_page\n",
    "\n",
    "        continue_blog = True\n",
    "        while continue_blog == True:\n",
    "            blog_page_url = blog_url + page_prefix + str(pull_page)\n",
    "\n",
    "            #sleep(random.uniform(1, 3))\n",
    "            url_test = requests.get(blog_page_url)\n",
    "            if url_test != \"<Response [404]>\":\n",
    "                soup2 = BS(url_test.content, 'html.parser')\n",
    "                for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                    blog_url1 = blog.find('a')\n",
    "                    blog_url2 = blog_url1['href']\n",
    "                    temp_list = []\n",
    "                    temp_list.append(blog_url2)\n",
    "                    ############\n",
    "                    df_post_content = pscrape.full_scrape(temp_list, \"yes\")\n",
    "                    ############\n",
    "\n",
    "                    ############\n",
    "                    blog_pk = oracledb.database_insert_oracle(df_post_content, sql_connections)\n",
    "                    ############\n",
    "                    if blog_pk == -1:\n",
    "                        update_system_status_values('patheos_url_error.ini', blog_name[4], str(p), blog_page_url)\n",
    "                    else:\n",
    "                        # UPDATES SAVE POINT FILE WITH CURRENT WORKING LOCATION\n",
    "                        update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Category', list_name)\n",
    "                        update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog', blog_name[4])\n",
    "                        update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog-Key', blog_pk)\n",
    "                        update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Page', pull_page)\n",
    "\n",
    "                    url_list.append(blog_url2)\n",
    "                    tposts += 1\n",
    "                    #return_dict[list_name].append(blog_url2)\n",
    "                    sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \" \n",
    "                                         + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                         + \" | page: \" + str(pull_page) \n",
    "                                         + \" | posts: \" + str(tposts))\n",
    "                pull_page = pull_page + 1\n",
    "                sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                     + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                     + \" | page: \" + str(pull_page) \n",
    "                                     + \" | posts: \" + str(tposts))\n",
    "            else:\n",
    "                continue_blog = False\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                 + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                 + \" | page: \" + str(pull_page) \n",
    "                                 + \" | posts: \" + str(tposts))\n",
    "        sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                             + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                             + \" | page: \" + str(pull_page) \n",
    "                             + \" | posts: \" + str(tposts))\n",
    "    #else:\n",
    "        #break\n",
    "        cnumber += 1\n",
    "        df_temp = pd.DataFrame({'Post URL':url_list})\n",
    "        #print(df_temp)\n",
    "        csv_name = blog_name[4] + '.csv'\n",
    "        df_temp.to_csv(csv_name)\n",
    "\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    oracledb.database_close_oracle(sql_connections)\n",
    "    ############\n",
    "    return url_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        for i, row in enumerate(input_df.itertuples(), 1):\n",
    "            row.blog_url:\n",
    "            \n",
    "        # reference specific attribute in row through \"row.[column name]\"\n",
    "    #return_dict = {}\n",
    "    cnumber = 1\n",
    "    for e in pages_url_list:\n",
    "        if e:\n",
    "            blog_name = e.rsplit(\"/\")\n",
    "            pages = exists_config_file(file, list_name, blog_name[4])\n",
    "            \n",
    "            blog_test = requests.get(e, timeout=5)\n",
    "            blog_url = blog_test.url\n",
    "            tposts = 0\n",
    "            pull_page = 1\n",
    "            continue_blog = True\n",
    "            \n",
    "            while continue_blog == True:\n",
    "                blog_page_url = blog_url + page_prefix + str(pull_page)\n",
    "                #sleep(random.uniform(1, 3))\n",
    "                url_test = requests.get(blog_page_url)\n",
    "                if url_test != \"<Response [404]>\":\n",
    "                    soup2 = BS(url_test.content, 'html.parser')\n",
    "                    for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                        blog_url1 = blog.find('a')\n",
    "                        blog_url2 = blog_url1['href']\n",
    "                        temp_list = []\n",
    "                        temp_list.append(blog_url2)\n",
    "                        ############\n",
    "                        df_post_content = pscrape.full_scrape(temp_list, \"yes\")\n",
    "                        ############\n",
    "\n",
    "                        ############\n",
    "                        blog_pk = oracledb.database_insert_oracle(df_post_content, sql_connections)\n",
    "                        ############\n",
    "                        if blog_pk == -1:\n",
    "                            update_system_status_values('patheos_url_error.ini', blog_name[4], str(p), blog_page_url)\n",
    "                        else:\n",
    "                            # UPDATES SAVE POINT FILE WITH CURRENT WORKING LOCATION\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Category', list_name)\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog', blog_name[4])\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog-Key', blog_pk)\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Page', pull_page)\n",
    "                        \n",
    "                        url_list.append(blog_url2)\n",
    "                        tposts += 1\n",
    "                        #return_dict[list_name].append(blog_url2)\n",
    "                        sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \" \n",
    "                                             + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                             + \" | page: \" + str(pull_page) \n",
    "                                             + \" | posts: \" + str(tposts))\n",
    "                    pull_page = pull_page + 1\n",
    "                    sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                         + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                         + \" | page: \" + str(pull_page) \n",
    "                                         + \" | posts: \" + str(tposts))\n",
    "                else:\n",
    "                    continue_blog = False\n",
    "                sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                     + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                     + \" | page: \" + str(pull_page) \n",
    "                                     + \" | posts: \" + str(tposts))\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                 + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                 + \" | page: \" + str(pull_page) \n",
    "                                 + \" | posts: \" + str(tposts))\n",
    "        #else:\n",
    "            #break\n",
    "            cnumber += 1\n",
    "            df_temp = pd.DataFrame({'Post URL':url_list})\n",
    "            #print(df_temp)\n",
    "            csv_name = blog_name[4] + '.csv'\n",
    "            df_temp.to_csv(csv_name)\n",
    "\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    oracledb.database_close_oracle(sql_connections)\n",
    "    ############\n",
    "    return url_list\n",
    "    #return return_dict\n",
    "\n",
    "#test_list = pass_dict_list(blog_dict, 'patheos_blogs_pages.ini')\n",
    "    \n",
    "#posts_list = fetch_page_posts(url_list)\n",
    "blog_dict = fetch_blogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetch blog urls for each category: 100%|██████████| 20/20 [00:17<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATHOLIC-BLOGS | category number: 1/79"
     ]
    }
   ],
   "source": [
    "def main_full_url_scrape():\n",
    "    blog_dict = fetch_blogs()\n",
    "    keep = True\n",
    "    for i in blog_dict:\n",
    "        #while keep == True:\n",
    "            #keep = False\n",
    "            #for b in blog_dict['progressive-christian-blogs']:\n",
    "                #print(b)\n",
    "        new_list = blog_find_pages(blog_dict[i], i)\n",
    "            #blog_find_pages(blog_dict['buddhist-blogs'], 'buddhist-blogs')\n",
    "    test_list = pass_dict_list(blog_dict, 'patheos_blogs_pages.ini')\n",
    "    for i in test_list:\n",
    "        print(i)\n",
    "        \n",
    "main_full_url_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blog_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For in file testing\n",
    "keep = True\n",
    "for i in blog_dict:\n",
    "    #while keep == True:\n",
    "        #keep = False\n",
    "        #for b in blog_dict['progressive-christian-blogs']:\n",
    "            #print(b)\n",
    "        new_list = blog_find_pages(blog_dict[i], i)\n",
    "        #new_list = blog_find_pages(blog_dict['progressive-christian-blogs'], 'progressive-christian-blogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in \n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For in file testing\n",
    "n = 0\n",
    "\n",
    "for i in blog_dict:\n",
    "    print(i, len(blog_dict[i]))\n",
    "    n = n + len(blog_dict[i])\n",
    "\n",
    "print(\"Total: \" + str(n))\n",
    "\n",
    "print(blog_dict['buddhist-blogs'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For in file testing\n",
    "n = 0\n",
    "\n",
    "for f in blog_dict['progressive-christian-blogs']:\n",
    "    print(f)\n",
    "    n = n + len(blog_dict['progressive-christian-blogs'])\n",
    "\n",
    "print(\"Total: \" + str(n))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "response_list = []\n",
    "\n",
    "teste = requests.get('https://www.patheos.com/blogs/jesuscrees')\n",
    "print(teste.status_code)\n",
    "print(teste.history)\n",
    "for i in teste.history:\n",
    "    response_list.append(i.status_code)\n",
    "    rget = i.status_code\n",
    "\n",
    "print(len(response_list))    \n",
    "print(rget)\n",
    "print(teste.url)\n",
    "\n",
    "test1 = teste.url\n",
    "\n",
    "test2 = requests.get(test1)\n",
    "print(test2.status_code)\n",
    "\n",
    "test = requests.get"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = requests.get('https://www.patheos.com/blogs/comingoutchristian')\n",
    "print(test.status_code)\n",
    "print(test.history)\n",
    "for i in test.history:\n",
    "    rget = i.status_code\n",
    "print(rget)\n",
    "print(test.url)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
