{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import unittest\n",
    "import random\n",
    "import datetime\n",
    "from time import sleep\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import parse_tns as tns\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from pandas.io.sql import SQLTable\n",
    "import cx_Oracle\n",
    "from sqlalchemy import types, create_engine\n",
    "#import webscrape_pd_scrape_patheos as pscrape\n",
    "import sys\n",
    "#import database_insert_oracle as oracledb\n",
    "#from passlib.hash import pbkdf2_sha256\n",
    "try:\n",
    "    from configparser import ConfigParser\n",
    "    from configparser import SafeConfigParser\n",
    "except ImportError:\n",
    "    from ConfigParser import ConfigParser  # ver. < 3.0\n",
    "    from ConfigParser import SafeConfigParser\n",
    "    \n",
    "HEADERS = {'user-agent': ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)'\n",
    "                          'AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "                          'Chrome/73.0.3683.114 Safari/537.36'),\n",
    "                          'referer': 'https://www.patheos.com/blogs/'}\n",
    "\n",
    "import webscrape_sql_insert_patheos as pinsert\n",
    "import webscrape_pd_scrape_patheos_notqdm as pscrape\n",
    "import webscrape_compare_current_patheos as pcompare\n",
    "import webscrape_process_results_main as pprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WILL BE SEPARATE .py TO  IMPORT\n",
    "def database_connect_oracle(db_user, db_password, database):\n",
    "    sql_connections = []\n",
    "    connection_string = db_user + '/' + db_password + database\n",
    "    print(\"\\n***CONNECTING***: \" + db_user + '/' + \"************\" + database + \"\\n--------------\")\n",
    "    con = cx_Oracle.connect(connection_string)\n",
    "    sql_connections.append(con)\n",
    "    con_engine = create_engine('oracle+cx_oracle://' + db_user + ':' + db_password + database) #'@192.168.86.108:5522/?service_name=xe')\n",
    "    sql_connections.append(con_engine)\n",
    "    return sql_connections\n",
    "\n",
    "def database_close_oracle(connection, sql_connections):\n",
    "    connection[0].close()\n",
    "    print(\"--------------\\n***DISCONNECTING***\\n\")\n",
    "\n",
    "def find_blog_pk(url, sql_connections):\n",
    "    con = sql_connections[0]\n",
    "    con_engine = sql_connections[1]\n",
    "    #print(url)\n",
    "    blog_number = pd.read_sql(\"SELECT blogs_number FROM patheos_blogs WHERE blogs_url = '\" + str(url) + \"'\", con_engine)\n",
    "    if blog_number.empty == False:\n",
    "        for i, row in enumerate(blog_number.itertuples(), 1):\n",
    "            pk = row.blogs_number\n",
    "    else:\n",
    "        pk = 9999\n",
    "    return pk\n",
    "\n",
    "def database_insert_oracle(input_df, sql_connections):\n",
    "    return_list = []\n",
    "    con = sql_connections[0]\n",
    "    con_engine = sql_connections[1]\n",
    "    total_process = input_df.shape[0]\n",
    "    invalid_category = []\n",
    "    invalid_blog = []\n",
    "    invalid_post = []\n",
    "    #connection_string = db_user + '/' + db_password + database\n",
    "    #print(\"\\n***CONNECTING***: \" + db_user + '/' + \"************\" + database + \"\\n--------------\")\n",
    "    #con = cx_Oracle.connect(connection_string)\n",
    "    #con_engine = create_engine('oracle+cx_oracle://' + db_user + ':' + db_password + '@192.168.86.108:5522/?service_name=xe')\n",
    "    \n",
    "    c = 0\n",
    "    ce = 0\n",
    "    b = 0\n",
    "    be = 0\n",
    "    p = 0\n",
    "    pdup = 0\n",
    "    pe = 0\n",
    "    \n",
    "    #(1) COMPARE TO EXISTING CATEGORIES:\n",
    "    for i, row in enumerate(input_df.itertuples(), 1): \n",
    "        try:\n",
    "            beliefs_test = pd.read_sql(\"SELECT * FROM patheos_beliefs WHERE beliefs_url = '\" + str(row.beliefs_url) + \"'\", con_engine)\n",
    "            if beliefs_test.empty == True:\n",
    "                cur = con.cursor()\n",
    "                cur.execute(\"SELECT MAX(beliefs_number) FROM patheos_beliefs\")\n",
    "                test_number = str(cur.fetchall()[0][0])\n",
    "                if test_number != 'None':\n",
    "                    new_number = int(test_number) + 1\n",
    "                else:\n",
    "                    new_number = 1                \n",
    "                beliefs_number = str(new_number)\n",
    "                cur.execute(\"\"\"INSERT INTO patheos_beliefs\n",
    "                                (BELIEFS_NUMBER, BELIEFS_NAME, BELIEFS_URL)\n",
    "                                VALUES\n",
    "                                ('\"\"\" + str(new_number) + \"\"\"','\"\"\" + row.beliefs_name + \"\"\"','\"\"\" + row.beliefs_url + \"\"\"')\"\"\")\n",
    "                con.commit()\n",
    "                cur2 = con.cursor()\n",
    "                cur2.execute(\"SELECT * FROM patheos_beliefs WHERE beliefs_number = '\" + str(new_number) + \"'\")\n",
    "                res = cur2.fetchall()\n",
    "                cur2.close()\n",
    "                cur.close()\n",
    "                c = c + 1\n",
    "            else:\n",
    "                cur3 = con.cursor()\n",
    "                cur3.execute(\"SELECT MAX(beliefs_number) FROM patheos_beliefs WHERE beliefs_url = '\" + row.beliefs_url + \"'\")\n",
    "                beliefs_number = str(cur3.fetchall()[0][0])\n",
    "                cur3.close()\n",
    "        except:\n",
    "            invalid_category.append(row.beliefs_url)\n",
    "            ce = ce + 1 \n",
    "        \n",
    "        return_list.append(beliefs_number)\n",
    "    #(2) COMPARE TO EXISTING BLOGS:\n",
    "        try:\n",
    "            blogs_test = pd.read_sql(\"SELECT * FROM patheos_blogs WHERE blogs_url = '\" + str(row.blogs_url) + \"'\", con_engine) \n",
    "                                        # beliefs_number = \" + beliefs_number + \" AND posts_url = '\" + str(row.blogs_url) + \"'\", con_engine)\n",
    "            #print(blogs_test)\n",
    "            if blogs_test.empty == True:\n",
    "                cur4 = con.cursor()\n",
    "                cur4.execute(\"SELECT MAX(blogs_number) FROM patheos_blogs\")\n",
    "                test_number2 = str(cur4.fetchall()[0][0])\n",
    "                if test_number2 != 'None':\n",
    "                    new_blog_number = int(test_number2) + 1\n",
    "                else:\n",
    "                    new_blog_number = 1                \n",
    "                blogs_number = str(new_blog_number)\n",
    "                cur4.execute(\"\"\"INSERT INTO patheos_blogs\n",
    "                                (BLOGS_NUMBER, BELIEFS_NUMBER, BLOGS_NAME, BLOGS_URL)\n",
    "                                VALUES\n",
    "                                ('\"\"\" + str(new_blog_number) + \"\"\"','\"\"\" + beliefs_number + \"\"\"','\"\"\" + row.blogs_name + \"\"\"','\"\"\" + row.blogs_url + \"\"\"')\"\"\")           \n",
    "                con.commit()\n",
    "                cur5 = con.cursor()\n",
    "                cur5.execute(\"SELECT * FROM patheos_blogs WHERE blogs_number = '\" + str(new_blog_number) + \"'\")\n",
    "                res2 = cur5.fetchall()\n",
    "                cur5.close()\n",
    "                cur4.close()\n",
    "                b = b + 1\n",
    "            else:\n",
    "                cur6 = con.cursor()\n",
    "                cur6.execute(\"SELECT MAX(blogs_number) FROM patheos_blogs WHERE blogs_url = '\" + row.blogs_url + \"'\")\n",
    "                blogs_number = str(cur6.fetchall()[0][0])\n",
    "                cur6.close()\n",
    "        except:\n",
    "            invalid_blog.append(row.blogs_url)\n",
    "            be = be + 1\n",
    "        return_list.append(blogs_number)\n",
    "    #(3) COMPARE TO EXISTING POSTS:\n",
    "        #new_post_number = -2\n",
    "        try:\n",
    "            posts_test = pd.read_sql(\"SELECT * FROM patheos_posts WHERE posts_url = '\" + str(row.posts_url) + \"'\", con_engine) \n",
    "                                    # beliefs_number = \" + beliefs_number + \" AND posts_url = '\" + str(row.blogs_url) + \"'\", con_engine)\n",
    "            #print(\"Found exising post url\")\n",
    "            if posts_test.empty == True:\n",
    "                cur7 = con.cursor()\n",
    "                cur7.execute(\"SELECT MAX(posts_number) FROM patheos_posts\")\n",
    "                test_number3 = str(cur7.fetchall()[0][0])\n",
    "                #print(\"Did not find existing. Max posts number = \" + test_number3)\n",
    "                if test_number3 != 'None':\n",
    "                    new_post_number = int(test_number3) + 1\n",
    "                else:\n",
    "                    new_post_number = 1 \n",
    "                posts_number = str(new_post_number)\n",
    "                var = cur7.var(cx_Oracle.CLOB)\n",
    "                var.setvalue(0, row.posts_content)    # write a small value first to force the temporary LOB to be created    \n",
    "                cur7.execute(\"\"\"INSERT INTO patheos_posts\n",
    "                                (POSTS_NUMBER, POSTS_TITLE, BLOGS_NUMBER, POSTS_AUTHOR, POSTS_DATE, POSTS_CONTENT, POSTS_URL)\n",
    "                                VALUES\n",
    "                                ('\"\"\" + str(new_post_number) + \"\"\"','\"\"\" + row.posts_title + \"\"\"','\"\"\" + blogs_number + \"\"\"','\"\"\" + row.posts_author + \"\"\"',\"\"\" \n",
    "                                      + \"\"\"to_date('\"\"\" + row.posts_date + \"\"\"','MONTH DD, YYYY'), :val ,'\"\"\" + row.posts_url + \"\"\"')\"\"\", val = var)   \n",
    "                con.commit()\n",
    "                #cur8 = con.cursor()\n",
    "                #cur8.execute(\"SELECT * FROM patheos_posts WHERE posts_number = '\" + str(new_post_number) + \"'\")\n",
    "                #res3 = cur8.fetchall()\n",
    "                #cur8.close()\n",
    "                #print(\"INSERTED POST: \" + str(res3) + \"\\n\")\n",
    "                cur7.close()\n",
    "                p = p + 1\n",
    "                return_code = 1\n",
    "            else:\n",
    "                cur9 = con.cursor()\n",
    "                cur9.execute(\"SELECT MAX(posts_number) FROM patheos_posts WHERE posts_url = '\" + row.posts_url + \"'\")\n",
    "                posts_number = str(cur9.fetchall()[0][0])\n",
    "                cur9.close()\n",
    "                pdup = pdup + 1\n",
    "                return_code = 2\n",
    "        except:\n",
    "            invalid_post.append(row.posts_url)\n",
    "            pe = pe + 1\n",
    "            return_code = 0\n",
    "            posts_number = -1\n",
    "        #posts_title posts_date posts_author posts_content posts_url blogs_name blogs_url beliefs_name beliefs_url\n",
    "        #sys.stdout.write('\\r'+ str(i) + \"/\" + str(total_process) + \" | BELIEFS: new(\" + str(c) + \") e(\" + str(ce) \n",
    "        #                                                         + \") | BLOGS: new(\" + str(b) + \") e(\" + str(be) \n",
    "        #                                                         + \") | POSTS: new(\" + str(p) + \") dup(\" + str(pdup) + \") e(\" + str(pe) + \")\")\n",
    "        #time.sleep(0.5)\n",
    "        #print('\\nposts_number: ' + posts_number)\n",
    "        return_list.append(posts_number) #2\n",
    "        return_list.append(c)       #3 beliefs new\n",
    "        return_list.append(ce)      #4 beliefs error\n",
    "        return_list.append(b)       #5 blogs new\n",
    "        return_list.append(be)      #6 blogs error\n",
    "        return_list.append(p)       #7 posts new\n",
    "        return_list.append(pdup)    #8 posts duplicate\n",
    "        return_list.append(pe)      #9 posts error\n",
    "    #print('from function: ')\n",
    "    #print(return_list)\n",
    "        \n",
    "    #print(\"\\nINSERT COMPLETE.\")\n",
    "    return return_list\n",
    "    #con.close()\n",
    "    #print(\"--------------\\n***DISCONNECTING***\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_system_status_values(file, section, option, value):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    cfgfile = open(file, 'w')\n",
    "    if config.has_section(section) == True:\n",
    "        config.set(section, option, value)\n",
    "    else:\n",
    "        config.add_section(section)\n",
    "        config.set(section, option, value)\n",
    "    config.write(cfgfile)\n",
    "    cfgfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_config_file(file, section, option):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    if config.has_option(section, option) == True:\n",
    "        page_number = int(config.get(section, option))\n",
    "    else:\n",
    "        page_number = 1\n",
    "    return page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_config_file(file):\n",
    "    config = ConfigParser()\n",
    "    config.read(file)\n",
    "    return_save = []\n",
    "    if config.has_option('SAVE POINT', 'Category') == True:\n",
    "        category = config.get('SAVE POINT', 'Category')\n",
    "        return_save.append(category)\n",
    "    else:\n",
    "        category = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Blog') == True:\n",
    "        blog = config.get('SAVE POINT', 'Blog')\n",
    "        return_save.append(blog)\n",
    "    else:\n",
    "        blog = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Blog-Key') == True:\n",
    "        blog_key = config.get('SAVE POINT', 'Blog-Key')\n",
    "        return_save.append(blog_key)\n",
    "    else:\n",
    "        blog_key = \"none\"\n",
    "    if config.has_option('SAVE POINT', 'Page') == True:\n",
    "        page = int(config.get('SAVE POINT', 'Page'))\n",
    "        return_save.append(page)\n",
    "    else:\n",
    "        page = 0\n",
    "           # list contains: [category, blog, blog_key, page]\n",
    "    return return_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patheos_urls_from_page(url, index=None):\n",
    "    url_test = requests.get(url)\n",
    "    if url_test != \"<Response [404]>\":\n",
    "        soup2 = BS(url_test.content, 'html.parser')\n",
    "        if index == None:\n",
    "            post_urls = []\n",
    "            for blog[0] in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                blog_url1 = blog.find('a')\n",
    "                blog_url2 = blog_url1['href']\n",
    "                post_urls.append(blog_url2)\n",
    "        else:\n",
    "            for blog[int(index)] in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                blog_url1 = blog.find('a')\n",
    "                blog_url2 = blog_url1['href']\n",
    "                post_urls = blog_url2\n",
    "    else:\n",
    "        if index == None:\n",
    "            post_urls = []\n",
    "        else:\n",
    "            post_urls = ''\n",
    "    return post_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_blogs():\n",
    "    url = 'http://www.patheos.com/blogs'\n",
    "    response = requests.get(url)\n",
    "    soup = BS(response.content, 'html.parser')\n",
    "\n",
    "    blog_list = []\n",
    "\n",
    "    for blog in soup.find_all('div', attrs={\"class\":\"related-content clearfix related-content-sm decorated channel-list\"}):\n",
    "        blog_url1 = blog.find('a')\n",
    "        blog_url2 = blog_url1['href']\n",
    "        blog_list.append(blog_url2) \n",
    "\n",
    "    blog_lists = []\n",
    "    \n",
    "    for i in blog_list:\n",
    "        split_url = i.rsplit(\"/\")\n",
    "        blog_name = split_url[3]\n",
    "        blog_lists.append(blog_name)\n",
    "    \n",
    "    #df_blog_dict = pd.DataFrame()\n",
    "    \n",
    "    blog_dict = {i:[] for i in blog_lists}\n",
    "\n",
    "    blog_cat_prefix = \"https://www.patheos.com/\"\n",
    "\n",
    "    i = 0    \n",
    "    for blog_urls in tqdm(blog_dict, desc='Fetch blog urls for each category'):\n",
    "        if blog_urls:\n",
    "            query_url = blog_cat_prefix + blog_urls\n",
    "            #sleep(random.uniform(1, 3))\n",
    "            subsub_blog = requests.get(query_url)\n",
    "            soup2 = BS(subsub_blog.content, 'html.parser')\n",
    "            for blog in soup2.find_all('div', attrs={\"class\":\"author-info\"}):\n",
    "                for blog_url0 in blog.find_all('div', attrs={\"class\":\"title\"}):\n",
    "                    blog_url1 = blog_url0.find('a')\n",
    "                    blog_url2 = blog_url1['href']\n",
    "                    blog_dict[blog_urls].append(blog_url2)\n",
    "\n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    #df_blog_dict.to_csv('category_blogurls.csv')\n",
    "    return blog_dict\n",
    "    #return df_blog_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_blog_dict(blog_dict, sql_connections):\n",
    "    df_results = pd.DataFrame(columns=('pk','category','blog_url'))\n",
    "    df_hold = pd.DataFrame(columns=('pk','category','blog_url'))\n",
    "    #df_results.set_index('pk')\n",
    "    #df_hold.set_index('pk')\n",
    "    for c in tqdm(blog_dict, desc='Fetching primary keys for blogs'):\n",
    "        for b in blog_dict[c]:\n",
    "            #print(\"\\nCategory: \" + c)\n",
    "            #print('\\nBlog: ' + b)\n",
    "            g_category = c\n",
    "            g_blog_url = b\n",
    "            blog_pk = find_blog_pk(b, sql_connections) #oracledb.find_blog_pk(b, sql_connections)\n",
    "            #print(blog_pk)\n",
    "            g_blog_pk = str(blog_pk)\n",
    "            #print(blog_pk)\n",
    "            if g_category and g_blog_url is not None:\n",
    "                if blog_pk != 9999:\n",
    "                    df_temp = pd.DataFrame([[g_blog_pk,      # blog db pk\n",
    "                                             g_category,     # blog name\n",
    "                                             g_blog_url]],    # blog url\n",
    "                                            columns=('pk','category','blog_url'))\n",
    "                    df_results = df_results.append(df_temp)\n",
    "                else:\n",
    "                    df_temp = pd.DataFrame([[g_blog_pk,\n",
    "                                             g_category,\n",
    "                                             g_blog_url]],\n",
    "                                            columns=('pk','category','blog_url'))\n",
    "                    df_hold = df_hold.append(df_temp)\n",
    "    # I'm banking on this adding the new entries to the bottom of the list and \n",
    "    # adding index numbers that are higher than the rest of the entries. These are\n",
    "    # not what the pk for these will end up being, but they will allow them to sit\n",
    "    # further down on the list than the save point location (i.e., they won't get missed)\n",
    "    df_results = df_results.append(df_hold, ignore_index=True)\n",
    "    #print(df_results.to_string())\n",
    "    return df_results\n",
    "        \n",
    "        \n",
    "# blog_dict structure:\n",
    "#  - dictionary name: blog_dict\n",
    "#  - key names: category\n",
    "#  - values: list of all category blog urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_404(blog, page_number, increment, name):\n",
    "    pn = 0\n",
    "    return_str = page_number\n",
    "    continue_on = True\n",
    "    if page_number < 1:\n",
    "        pn = increment\n",
    "        return_str = 0\n",
    "    else:\n",
    "        pn = page_number + increment    \n",
    "    blog_test = requests.get(blog, timeout=5)\n",
    "    blog_url = blog_test.url\n",
    "    while continue_on == True:\n",
    "        blog_page_url = blog_url + \"page/\" + str(pn)\n",
    "        if pn < 20000:\n",
    "            try:\n",
    "                url_test = requests.get(blog_page_url, timeout=5) #, allow_redirects=True)\n",
    "                #sleep(random.uniform(1, 3))\n",
    "                if url_test.status_code != 404:\n",
    "                    sys.stdout.write('\\r' + blog + \" | page(\" + str(pn) + \")\") # | category total: (\" + str(t) + \")\")\n",
    "                    return_str = pn\n",
    "                    pn = pn + increment\n",
    "                else:\n",
    "                    continue_on = False                \n",
    "            except:\n",
    "                return_str = -1\n",
    "                continue_on = False\n",
    "        else:\n",
    "            return_str = -2\n",
    "            continue_on = False\n",
    "    if increment == 1:\n",
    "        sys.stdout.write('\\r' + blog + \" | page(\" + str(return_str) + \")\") # | category total: (\" + str(t) + \")\")        \n",
    "    return return_str                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_find_pages(blogname_list, list_name):\n",
    "    c = 0\n",
    "    t = 1\n",
    "    b = 1\n",
    "    url_list = []\n",
    "    continue_on = True\n",
    "    #for i in blogname_list:\n",
    "    #    if i != \"\":\n",
    "    i = blogname_list\n",
    "    try:\n",
    "        continue_on = True\n",
    "        page_prefix = \"/page/\"\n",
    "        blog_name = i.rsplit(\"/\")\n",
    "        try:\n",
    "            p = int(exists_config_file('patheos_blogs_pages.ini', list_name, blog_name[4]))\n",
    "        except:\n",
    "            throw_away = 0\n",
    "        if not p:\n",
    "            p = 0\n",
    "        try:\n",
    "            p1 = test_404(i, p, 500, blog_name[4])\n",
    "        except:\n",
    "            throw_away = 0\n",
    "\n",
    "        try:\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "        except:\n",
    "            throw_away = 0\n",
    "\n",
    "        if ((p1 != -1) and (p1 != -2)):\n",
    "            p2 = test_404(i, p1, 100, blog_name[4])\n",
    "            p = p1\n",
    "            if p2 != -1:\n",
    "                p3 = test_404(i, p2, 50, blog_name[4])\n",
    "                p = p2\n",
    "                if p3 != -1:\n",
    "                    p4 = test_404(i, p3, 25, blog_name[4])\n",
    "                    p = p4\n",
    "\n",
    "        if ((p != -1) and (p != -2)):\n",
    "            while continue_on == True:    \n",
    "                sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "                p = test_404(i, p, 1, blog_name[4])\n",
    "                continue_on = False\n",
    "            t = t + p\n",
    "            b = b + 1\n",
    "            update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "        else:\n",
    "            update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "            b = b + 1\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "    except:\n",
    "        p = -1\n",
    "        update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "        sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "    return str(p)\n",
    "#else:\n",
    "#    update_system_status_values('patheos_blogs_pages.ini', list_name, blog_name[4], str(p))\n",
    "#    sys.stdout.write('\\r' + list_name.upper() + \" | category number: \" + str(b) + \"/\" + str(len(blogname_list)))\n",
    "\n",
    "fail_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_dict_list(blog_dict, file):\n",
    "    df_lists_results = pd.DataFrame()\n",
    "    \n",
    "    blog_posts = {i:[] for i in blog_dict}\n",
    "    for i in blog_dict:\n",
    "        #result_list = fetch_page_posts(i, blog_dict[i], file)\n",
    "        result_list = fetch_page_posts(i, blog_dict[i], file)\n",
    "        blog_posts[i].append(result_list)\n",
    "    return blog_posts #dictionary\n",
    "\n",
    "def fetch_page_posts(blog_dict, file, connection_info, csv=None): #(dictionary, string, list)\n",
    "#def fetch_page_posts(list_name, pages_url_list, file):\n",
    "    c = 0\n",
    "    ce = 0\n",
    "    b = 0\n",
    "    be = 0\n",
    "    p = 0\n",
    "    pdup = 0\n",
    "    pe = 0\n",
    "    blog_number = 0\n",
    "    url_list = []\n",
    "    url_errors = []\n",
    "    continue_on = True\n",
    "    page_prefix = \"page/\"\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    db_user = connection_info[0]\n",
    "    db_password = connection_info[1]\n",
    "    # user = connection_info[2]\n",
    "    database = connection_info[2]\n",
    "    sql_connections = database_connect_oracle(db_user, db_password, database) #oracledb.database_connect_oracle(db_user, db_password, user, database)\n",
    "    print(sql_connections)\n",
    "    ############\n",
    "    if csv == None:\n",
    "        input_df = convert_blog_dict(blog_dict, sql_connections)\n",
    "        input_df = input_df.sort_values(by=['pk','category','blog_url'])\n",
    "        input_df = input_df.reset_index(drop=True)\n",
    "        #print(input_df.to_string())\n",
    "        input_df.to_csv('sorted_blog_list.csv')\n",
    "    if csv == 1:\n",
    "        input_df = pd.read_csv('sorted_blog_list.csv')\n",
    "    \n",
    "    # RESTORE SAVE POINT PROCESS\n",
    "    save_point_list = save_point_config_file('patheos_save_point.ini')\n",
    "    print(save_point_list)\n",
    "    save_key = 0\n",
    "    if save_point_list:\n",
    "        if save_point_list[3] != 0:\n",
    "            save_category = save_point_list[0]\n",
    "            save_blog = save_point_list[1]\n",
    "            save_key = save_point_list[2]\n",
    "            save_page = save_point_list[3]\n",
    "            index_point = int(save_key)\n",
    "    else:\n",
    "        save_key = 0\n",
    "        save_page = 1\n",
    "        \n",
    "        # TEST SAVE POINT PAGE\n",
    "        #top_url = get_patheos_urls_from_page(save_page, 0)\n",
    "        #status_code = oracledb.database_post_compare(top_url, sql_connections)\n",
    "        #if status_code == 1: # found in database\n",
    "        #        \n",
    "        #    # TEST NEXT PAGE UNTIL SUCCESSUL\n",
    "        #    test_page = save_page\n",
    "        #    while status_code == 1:\n",
    "        #        test_page = test_page + 1\n",
    "        #        top_url = get_patheos_urls_from_page(test_page, 0)\n",
    "        #        status_code = oracledb.database_post_compare(top_url, sql_connections)\n",
    "        #    if status_code == 0: # not found in database\n",
    "        #        adjusted_save = test_page - 1\n",
    "        #else:\n",
    "        #    adjusted_save = save_page\n",
    "    pull_page = save_page\n",
    "    second_loop = False\n",
    "    \n",
    "    if (index_point > 0) and (int(save_page) > 0):\n",
    "        index_point = index_point - 1\n",
    "        #print(index_point)\n",
    "        input_df = input_df[index_point:] #input_df.loc[index_point:]\n",
    "    #print(index_point)\n",
    "    \n",
    "    #print(input_df.to_string())\n",
    "    \n",
    "    #for i in islice(input_df.itertuples(), save_key, None): #, row in islice(input_df.itertuples(), save_key, None):\n",
    "    for i, row in enumerate(input_df.itertuples(), 0): #, row in islice(input_df.itertuples(), save_key, None):\n",
    "        total_pages = blog_find_pages(row.blog_url, row.category)\n",
    "        #print(row.blog_url)\n",
    "        blog_name = row.blog_url.rsplit(\"/\")\n",
    "        blog_test = requests.get(row.blog_url, timeout=5)\n",
    "        blog_url = blog_test.url\n",
    "        tposts = 0\n",
    "        if second_loop == True:\n",
    "            pull_page = 1\n",
    "        continue_blog = True\n",
    "        #print(\"ARE WE GOING BACK UP HERE?\")\n",
    "        while continue_blog == True:\n",
    "            blog_page_url = blog_url + page_prefix + str(pull_page)\n",
    "\n",
    "            #sleep(random.uniform(1, 3))\n",
    "            url_test = requests.get(blog_page_url)\n",
    "            #print('\\n' + str(url_test) + ' continue_blog = ' + str(continue_blog))\n",
    "            if str(url_test) != \"<Response [404]>\":\n",
    "                #print(str(url_test))\n",
    "                #print(\"DO WE COME HERE TWICE?\")\n",
    "                soup2 = BS(url_test.content, 'html.parser')\n",
    "                for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                    blog_url1 = blog.find('a')\n",
    "                    blog_url2 = blog_url1['href']\n",
    "                    temp_list = []\n",
    "                    temp_list.append(blog_url2)\n",
    "                    #for i in temp_list:\n",
    "                    #    print('\\ntemp_list: ' + i)\n",
    "                    sleep(random.uniform(0, 2))\n",
    "                    ############\n",
    "                    #print(temp_list)\n",
    "                    df_post_content = pscrape.full_scrape(temp_list, \"yes\")\n",
    "                    #print('\\n' + df_post_content.to_string())\n",
    "                    ############\n",
    "\n",
    "                    ############\n",
    "                    if df_post_content.empty == True:\n",
    "                        #url_errors.append(blog_url2)\n",
    "                        #error_time = datetime.datetime.now()\n",
    "                        #update_system_status_values('empty_dataframe_error.ini', blog_name[4], str(error_time) + ' ' \n",
    "                        #                            + str(tposts + 1), blog_url2)\n",
    "                        with open(r'full_url_errors.csv','a', newline='') as fd:\n",
    "                            fd.write(blog_url2 + '\\n\\r')\n",
    "                        blog_number = -2\n",
    "                        pe = pe + 1\n",
    "                    else:\n",
    "                        return_pk = database_insert_oracle(df_post_content, sql_connections) #oracledb.database_insert_oracle(df_post_content, sql_connections)\n",
    "                        #print()\n",
    "                        #print(return_pk)\n",
    "                        ############\n",
    "                        # return_pk CONTAINS THE FOLLOW LIST (by list index location)\n",
    "                        #0 categories primary key\n",
    "                        blog_number = return_pk[1] #1 blogs primary key\n",
    "                        #2 posts primary key\n",
    "                        c = c + return_pk[3] #3 beliefs new\n",
    "                        ce = c + return_pk[4] #4 beliefs error\n",
    "                        b = b + return_pk[5] #5 blogs new\n",
    "                        be = be + return_pk[6] #6 blogs error\n",
    "                        p = p + return_pk[7] #7 posts new\n",
    "                        pdup = pdup + return_pk[8] #8 posts duplicate\n",
    "                        pe = pe + return_pk[9] #9 posts error\n",
    "                        ############\n",
    "                        if return_pk[2] == -1:\n",
    "                            update_system_status_values('patheos_url_error.ini', blog_name[4], str(p), blog_page_url)\n",
    "                        else:\n",
    "                            # UPDATES SAVE POINT FILE WITH CURRENT WORKING LOCATION\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Category', row.category)\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog', blog_name[4])\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog-Key', str(return_pk[1]))\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Page', str(pull_page))\n",
    "\n",
    "                    url_list.append(blog_url2)\n",
    "                    tposts += 1\n",
    "                    #return_dict[list_name].append(blog_url2)\n",
    "                    sys.stdout.write('\\r' + row.category.upper() + \": \" + blog_name[4] \n",
    "                                          + \" | blog number: \" + str(blog_number)\n",
    "                                          + \" | page: \" + str(pull_page) + \"/\" + str(total_pages)\n",
    "                                          + \" | posts: \" + str(tposts)\n",
    "                                          + \" | BELIEFS: new(\" + str(c) + \") e(\" + str(ce) \n",
    "                                          + \") | BLOGS: new(\" + str(b) + \") e(\" + str(be)\n",
    "                                          + \") | POSTS: new(\" + str(p) + \") dup(\" + str(pdup) + \") e(\" + str(pe) + \")\")\n",
    "                pull_page = pull_page + 1\n",
    "                sys.stdout.write('\\r' + row.category.upper() + \": \" + blog_name[4] \n",
    "                                          + \" | blog number: \" + str(blog_number)\n",
    "                                          + \" | page: \" + str(pull_page) + \"/\" + str(total_pages)\n",
    "                                          + \" | posts: \" + str(tposts)\n",
    "                                          + \" | BELIEFS: new(\" + str(c) + \") e(\" + str(ce) \n",
    "                                          + \") | BLOGS: new(\" + str(b) + \") e(\" + str(be)\n",
    "                                          + \") | POSTS: new(\" + str(p) + \") dup(\" + str(pdup) + \") e(\" + str(pe) + \")\")\n",
    "            else:\n",
    "                continue_blog = False\n",
    "                second_loop = True\n",
    "            sys.stdout.write('\\r' + row.category.upper() + \": \" + blog_name[4] \n",
    "                                          + \" | blog number: \" + str(blog_number)\n",
    "                                          + \" | page: \" + str(pull_page) + \"/\" + str(total_pages)\n",
    "                                          + \" | posts: \" + str(tposts)\n",
    "                                          + \" | BELIEFS: new(\" + str(c) + \") e(\" + str(ce) \n",
    "                                          + \") | BLOGS: new(\" + str(b) + \") e(\" + str(be)\n",
    "                                          + \") | POSTS: new(\" + str(p) + \") dup(\" + str(pdup) + \") e(\" + str(pe) + \")\")\n",
    "        sys.stdout.write('\\r' + row.category.upper() + \": \" + blog_name[4] \n",
    "                                          + \" | blog number: \" + str(blog_number)\n",
    "                                          + \" | page: \" + str(pull_page) + \"/\" + str(total_pages)\n",
    "                                          + \" | posts: \" + str(tposts)\n",
    "                                          + \" | BELIEFS: new(\" + str(c) + \") e(\" + str(ce) \n",
    "                                          + \") | BLOGS: new(\" + str(b) + \") e(\" + str(be)\n",
    "                                          + \") | POSTS: new(\" + str(p) + \") dup(\" + str(pdup) + \") e(\" + str(pe) + \")\")\n",
    "    #else:\n",
    "        #break\n",
    "        #cnumber += 1\n",
    "        df_temp = pd.DataFrame({'Post URL':url_list})\n",
    "        #print(df_temp)\n",
    "        csv_name = blog_name[4] + '.csv'\n",
    "        df_temp.to_csv('\\blog_url_lists\\\\' + csv_name)\n",
    "\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    database_close_oracle(sql_connections) #oracledb.database_close_oracle(sql_connections)\n",
    "    ############\n",
    "    return url_list\n",
    "\n",
    "#blog_dict = fetch_blogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_connection_list(db_user, db_password, database):\n",
    "    connection_info_list = []\n",
    "    connection_info_list.append(db_user)\n",
    "    connection_info_list.append(db_password)\n",
    "    #connection_info_list.append(user)\n",
    "    connection_info_list.append(database)\n",
    "    return connection_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@localhost:1521/xe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetch blog urls for each category: 100%|██████████| 20/20 [00:07<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***CONNECTING***: system/************@localhost:1521/xe\n",
      "--------------\n",
      "[<cx_Oracle.Connection to system@localhost:1521/xe>, Engine(oracle+cx_oracle://system:***@localhost:1521/xe)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching primary keys for blogs: 100%|██████████| 20/20 [00:11<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buddhist-blogs', 'wildfoxzen', '6', 5]\n",
      "BUDDHIST-BLOGS: wildfoxzen | blog number: 6 | page: 8/84 | posts: 36 | BELIEFS: new(0) e(0) | BLOGS: new(0) e(0) | POSTS: new(12) dup(23) e(1)"
     ]
    }
   ],
   "source": [
    "def main_full_url_scrape():\n",
    "    # TNSNAMES INFO\n",
    "    tnsnames_path = \"\"\n",
    "    server = \"LOCALHOST\"\n",
    "    database_str = tns.parse_tnsnames(tnsnames_path, server)\n",
    "    print(database_str)\n",
    "    # GATHER OTHER CONNECTION INFO\n",
    "    #database_user = \"no_input\".upper() #input(\"Xnumber or Banner Username: \")\n",
    "    database_user = 'system'\n",
    "    database_password = 'oracle' #getpass.getpass(environment_user + \" Password: \")\n",
    "    connection_info = build_connection_list(database_user, database_password, database_str)\n",
    "    blog_dict = fetch_blogs()\n",
    "    fetch_page_posts(blog_dict, 'patheos_blogs_pages.ini', connection_info)\n",
    "    \n",
    "main_full_url_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_full_url_scrape()\n",
    "fetch_page_posts(blog_dict, 'patheos_blogs_pages.ini', connection_info, csv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blog_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For in file testing\n",
    "keep = True\n",
    "for i in blog_dict:\n",
    "    #while keep == True:\n",
    "        #keep = False\n",
    "        #for b in blog_dict['progressive-christian-blogs']:\n",
    "            #print(b)\n",
    "        new_list = blog_find_pages(blog_dict[i], i)\n",
    "        #new_list = blog_find_pages(blog_dict['progressive-christian-blogs'], 'progressive-christian-blogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in \n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For in file testing\n",
    "n = 0\n",
    "\n",
    "for i in blog_dict:\n",
    "    print(i, len(blog_dict[i]))\n",
    "    n = n + len(blog_dict[i])\n",
    "\n",
    "print(\"Total: \" + str(n))\n",
    "\n",
    "print(blog_dict['buddhist-blogs'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For in file testing\n",
    "n = 0\n",
    "\n",
    "for f in blog_dict['progressive-christian-blogs']:\n",
    "    print(f)\n",
    "    n = n + len(blog_dict['progressive-christian-blogs'])\n",
    "\n",
    "print(\"Total: \" + str(n))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "response_list = []\n",
    "\n",
    "teste = requests.get('https://www.patheos.com/blogs/jesuscrees')\n",
    "print(teste.status_code)\n",
    "print(teste.history)\n",
    "for i in teste.history:\n",
    "    response_list.append(i.status_code)\n",
    "    rget = i.status_code\n",
    "\n",
    "print(len(response_list))    \n",
    "print(rget)\n",
    "print(teste.url)\n",
    "\n",
    "test1 = teste.url\n",
    "\n",
    "test2 = requests.get(test1)\n",
    "print(test2.status_code)\n",
    "\n",
    "test = requests.get"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = requests.get('https://www.patheos.com/blogs/comingoutchristian')\n",
    "print(test.status_code)\n",
    "print(test.history)\n",
    "for i in test.history:\n",
    "    rget = i.status_code\n",
    "print(rget)\n",
    "print(test.url)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        for i, row in enumerate(input_df.itertuples(), 1):\n",
    "            row.blog_url:\n",
    "            \n",
    "        # reference specific attribute in row through \"row.[column name]\"\n",
    "    #return_dict = {}\n",
    "    cnumber = 1\n",
    "    for e in pages_url_list:\n",
    "        if e:\n",
    "            blog_name = e.rsplit(\"/\")\n",
    "            pages = exists_config_file(file, list_name, blog_name[4])\n",
    "            \n",
    "            blog_test = requests.get(e, timeout=5)\n",
    "            blog_url = blog_test.url\n",
    "            tposts = 0\n",
    "            pull_page = 1\n",
    "            continue_blog = True\n",
    "            \n",
    "            while continue_blog == True:\n",
    "                blog_page_url = blog_url + page_prefix + str(pull_page)\n",
    "                #sleep(random.uniform(1, 3))\n",
    "                url_test = requests.get(blog_page_url)\n",
    "                if url_test != \"<Response [404]>\":\n",
    "                    soup2 = BS(url_test.content, 'html.parser')\n",
    "                    for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                        blog_url1 = blog.find('a')\n",
    "                        blog_url2 = blog_url1['href']\n",
    "                        temp_list = []\n",
    "                        temp_list.append(blog_url2)\n",
    "                        ############\n",
    "                        df_post_content = pscrape.full_scrape(temp_list, \"yes\")\n",
    "                        ############\n",
    "\n",
    "                        ############\n",
    "                        blog_pk = oracledb.database_insert_oracle(df_post_content, sql_connections)\n",
    "                        ############\n",
    "                        if blog_pk == -1:\n",
    "                            update_system_status_values('patheos_url_error.ini', blog_name[4], str(p), blog_page_url)\n",
    "                        else:\n",
    "                            # UPDATES SAVE POINT FILE WITH CURRENT WORKING LOCATION\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Category', list_name)\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog', blog_name[4])\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Blog-Key', blog_pk)\n",
    "                            update_system_status_values('patheos_save_point.ini', 'SAVE POINT', 'Page', pull_page)\n",
    "                        \n",
    "                        url_list.append(blog_url2)\n",
    "                        tposts += 1\n",
    "                        #return_dict[list_name].append(blog_url2)\n",
    "                        sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \" \n",
    "                                             + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                             + \" | page: \" + str(pull_page) \n",
    "                                             + \" | posts: \" + str(tposts))\n",
    "                    pull_page = pull_page + 1\n",
    "                    sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                         + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                         + \" | page: \" + str(pull_page) \n",
    "                                         + \" | posts: \" + str(tposts))\n",
    "                else:\n",
    "                    continue_blog = False\n",
    "                sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                     + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                     + \" | page: \" + str(pull_page) \n",
    "                                     + \" | posts: \" + str(tposts))\n",
    "            sys.stdout.write('\\r' + list_name.upper() + \": \" + blog_name[4] + \" | blog number: \"\n",
    "                                 + str(cnumber) + \"/\" + str(len(pages_url_list)) \n",
    "                                 + \" | page: \" + str(pull_page) \n",
    "                                 + \" | posts: \" + str(tposts))\n",
    "        #else:\n",
    "            #break\n",
    "            cnumber += 1\n",
    "            df_temp = pd.DataFrame({'Post URL':url_list})\n",
    "            #print(df_temp)\n",
    "            csv_name = blog_name[4] + '.csv'\n",
    "            df_temp.to_csv(csv_name)\n",
    "\n",
    "    ############ NEED TO PROVIDE VARIABLES\n",
    "    oracledb.database_close_oracle(sql_connections)\n",
    "    ############\n",
    "    return url_list\n",
    "    #return return_dict\n",
    "\n",
    "#test_list = pass_dict_list(blog_dict, 'patheos_blogs_pages.ini')\n",
    "    \n",
    "#posts_list = fetch_page_posts(url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
