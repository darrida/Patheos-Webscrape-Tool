{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from urllib.request import urlopen, URLError\n",
    "from tqdm import tqdm\n",
    "import colorama\n",
    "import parse_tns as tns\n",
    "from sqlalchemy import types, create_engine\n",
    "from pandas.io.sql import SQLTable\n",
    "import cx_Oracle\n",
    "import sys\n",
    "import webscrape_sql_insert_patheos as pinsert\n",
    "import webscrape_pd_scrape_patheos as pscrape\n",
    "import webscrape_compare_current_patheos as pcompare\n",
    "import webscrape_process_results_main as pprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blog = \"https://www.patheos.com/blogs/jesuscreed/\"\n",
    "blog = \"https://www.patheos.com/blogs/keithgiles/\"\n",
    "page_prefix = \"page/\"\n",
    "p = 1\n",
    "#blog_page_url = blog + page_prefix + str(p)\n",
    "number_list = [1,2,3,4,5,6,7,8,9]\n",
    "number_list = []\n",
    "p = 1\n",
    "url_list = []\n",
    "continue_on = True\n",
    "#while p < 100:\n",
    "#    number_list.append(p)\n",
    "#    p = p + 1\n",
    "\n",
    "while continue_on == True:\n",
    "    blog_page_url = blog + page_prefix + str(p)\n",
    "    url_test = requests.get(blog_page_url)\n",
    "    if url_test.status_code != 404:\n",
    "        url_list.append(blog_page_url)\n",
    "        print(blog_page_url)\n",
    "        p = p + 1\n",
    "        continue_on = True\n",
    "    else:\n",
    "        continue_on = False\n",
    "    \n",
    "#for i in url_list:\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subblog_list = []\n",
    "\n",
    "while True:\n",
    "    i = 0    \n",
    "    for blog_urls in tqdm(url_list, desc='Fetch Post URLs from Blogs (pass 1)'):\n",
    "#        print(blog_urls)\n",
    "        if blog_urls: # and (i < 10):\n",
    "        #if blog_urls:\n",
    "            subsub_blog = requests.get(blog_urls)\n",
    "            #print(subsub_blog)\n",
    "            if subsub_blog != \"<Response [404]>\":\n",
    "                soup2 = BS(subsub_blog.content, 'html.parser')\n",
    "                for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                    #print(\"test: \" + blog)\n",
    "                    blog_url1 = blog.find('a')\n",
    "                    #print(blog_url1)\n",
    "                    blog_url2 = blog_url1['href']\n",
    "                    #print(blog_url2)\n",
    "                    #blog_dict[blog.text] \n",
    "                #print(soup2.prettify)\n",
    "                #for a in soup2.find_all('a', href=True):\n",
    "                    subblog_list.append(blog_url2)\n",
    "                #print(\"FINISHED \" + blog_urls)  \n",
    "                i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for i in subblog_list:\n",
    "    print(i)\n",
    "\n",
    "len(subblog_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subblog_list = []\n",
    "\n",
    "while True:\n",
    "    i = 0    \n",
    "    for blog_urls in tqdm(url_list, desc='Fetch Post URLs from Blogs (pass 1)'):\n",
    "#        print(blog_urls)\n",
    "        if blog_urls: # and (i < 10):\n",
    "        #if blog_urls:\n",
    "            subsub_blog = requests.get(blog_urls)\n",
    "            soup2 = BS(subsub_blog.content, 'html.parser')\n",
    "            for blog in soup2.find_all('h2', attrs={\"class\":\"entry-title\"}):\n",
    "                #print(blog)\n",
    "                blog_url1 = blog.find('a')\n",
    "                #print(blog_url1)\n",
    "                blog_url2 = blog_url1['href']\n",
    "                #print(blog_url2)\n",
    "                #blog_dict[blog.text] \n",
    "            #print(soup2.prettify)\n",
    "            #for a in soup2.find_all('a', href=True):\n",
    "                subblog_list.append(blog_url2)\n",
    "            #print(\"FINISHED \" + blog_urls)  \n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "len(subblog_list)    \n",
    "for i in subblog_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Remove duplicate blog post urls.\")\n",
    "unique_subblog_list = list(set(subblog_list))\n",
    "#unique_subblog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_subblog_list)\n",
    "#unique_subblog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "final_real_post = []\n",
    "\n",
    "url_real_prefix = 'https://www.patheos.com/blogs/'\n",
    "\n",
    "for post_url in tqdm(unique_subblog_list):\n",
    "    #print(post_url)\n",
    "    for blog_name in final_bname:\n",
    "        test_url = url_real_prefix + blog_name\n",
    "        #i = 2010\n",
    "        #while (i < 2020):\n",
    "        for y in year:\n",
    "            if post_url.startswith(test_url + \"/\" + str(y)):\n",
    "                final_real_post.append(post_url)\n",
    "            #i = i + 1\n",
    "#final_real_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_real_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_posts = list(set(final_real_post))\n",
    "len(individual_posts)\n",
    "\n",
    "comments1 = \"#disqus_thread\"\n",
    "\n",
    "list_without_disqus = []\n",
    "\n",
    "for word3 in individual_posts:\n",
    "    if not word3.endswith(comments1):\n",
    "        #individual_posts.remove(word3)\n",
    "        list_without_disqus.append(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(individual_posts)\n",
    "len(list_without_disqus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts_only = []\n",
    "\n",
    "for word4 in list_without_disqus:\n",
    "    count_list = word4.rsplit(\"/\")\n",
    "    count = len(count_list)\n",
    "    if (count > 8):\n",
    "        list_posts_only.append(word4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_posts_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped_urls = pd.DataFrame(list_posts_only)\n",
    "#df_new_urls.to_csv('patheos_posts.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def main():\n",
    "    tnsnames_path = \"\"\n",
    "    server = \"PATHEOSDBAPEX\"\n",
    "    df_scraped_urls = pd.DataFrame\n",
    "    environment = tns.parse_tnsnames(tnsnames_path, server)\n",
    "    print(environment)\n",
    "    database_user = \"no_input\" #input(\"Xnumber or Banner Username: \")\n",
    "    database_user = database_user.upper()\n",
    "    #banner_database = environment_select(input(\"Banner database: \"))\n",
    "    #environment_user = (\"Data base user: \")\n",
    "    environment_user = 'system'\n",
    "    environment_password = 'oracle' #getpass.getpass(environment_user + \" Password: \")\n",
    "    temp_list = pprocess.process_results(pcompare.access_compare_query(environment_user, environment_password, database_user, environment, df_scraped_urls))\n",
    "    temp_df = pscrape.full_scrape(temp_list)\n",
    "    pprocess.process_results(pinsert.access_insert_execute(environment_user, environment_password, database_user, environment, temp_df))\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "main()\n",
    "#df_test = main()\n",
    "\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_excel('patheos_posts_content.xlsx')\n",
    "df_results.to_csv('patheos_posts_content.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
