{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from urllib.request import urlopen, URLError\n",
    "from tqdm import tqdm\n",
    "import colorama\n",
    "import parse_tns as tns\n",
    "from sqlalchemy import types, create_engine\n",
    "from pandas.io.sql import SQLTable\n",
    "import cx_Oracle\n",
    "import sys\n",
    "import webscrape_sql_insert_patheos as pinsert\n",
    "import webscrape_pd_scrape_patheos as pscrape\n",
    "import webscrape_compare_current_patheos as pcompare\n",
    "import webscrape_process_results_main as pprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.patheos.com/blogs'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.content, 'html.parser')\n",
    "#soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_dict = {}\n",
    "url_list1 = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    for blog in soup.find_all('div', attrs={\"class\":\"col-sm-6\"})[0:20]:\n",
    "        blogurl = blog.find('a')\n",
    "        blog_dict[blog.text] = blogurl['href']\n",
    "    i = 0    \n",
    "    for urls in tqdm(blog_dict.values(), desc='Fetch Blogs from Categories'):\n",
    "#        print(urls)\n",
    "        if urls and (i < 2):\n",
    "            sub_blog = requests.get(urls)\n",
    "            soup1 = BS(sub_blog.content, 'html.parser')\n",
    "            soup1.prettify\n",
    "            for a in soup1.find_all('a', href=True):\n",
    "                url_list1.append(a['href'])\n",
    "            #print(\"FINISHED \" + urls)\n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'Strip items that start with /, #, www.'\")\n",
    "unique_blogs = list(set(url_list1))\n",
    "prefixes = ('/','#','www.')\n",
    "i = 0\n",
    "for word in unique_blogs:\n",
    "    if word.startswith(prefixes):\n",
    "        unique_blogs.remove(word)\n",
    "#unique_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_blogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remove non-Blog Title URLS.\")\n",
    "prefixes2 = ('http://www.patheos.com/blogs/')\n",
    "for word2 in unique_blogs:\n",
    "    if not word2.startswith(prefixes2):\n",
    "        unique_blogs.remove(word2)\n",
    "#unique_blogs\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_blogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses .split() to designate the \"/\" as the marker between sections, \n",
    "# which grabs the text after section 4, but does not include section 5.\n",
    "print(\"Fetch just blogs names.\")\n",
    "final_bname = []\n",
    "url_prefix = 'http://www.patheos.com/blogs/'\n",
    "for url_blog in unique_blogs:\n",
    "    url_bname = url_blog.split(\"/\",5)[4:5]\n",
    "    for words in url_bname:\n",
    "        final_bname.append(words)     \n",
    "#final_bname\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Append blog name to 'http://www.patheos.com/blogs/'\")\n",
    "final_url = [url_prefix + x for x in final_bname]\n",
    "#final_url\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Strip out duplicates.\")\n",
    "final_url_dedupe = list(set(final_url))\n",
    "len(final_url_dedupe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subblog_list = []\n",
    "\n",
    "while True:\n",
    "    i = 0    \n",
    "    for blog_urls in tqdm(final_url_dedupe, desc='Fetch Post URLs from Blogs (pass 1)'):\n",
    "#        print(blog_urls)\n",
    "        if blog_urls: # and (i < 10):\n",
    "        #if blog_urls:\n",
    "            subsub_blog = requests.get(blog_urls)\n",
    "            soup2 = BS(subsub_blog.content, 'html.parser')\n",
    "            #print(soup2.prettify)\n",
    "            for a in soup2.find_all('a', href=True):\n",
    "                subblog_list.append(a['href'])\n",
    "            #print(\"FINISHED \" + blog_urls)  \n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Remove duplicate blog post urls.\")\n",
    "unique_subblog_list = list(set(subblog_list))\n",
    "#unique_subblog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_subblog_list)\n",
    "#unique_subblog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "final_real_post = []\n",
    "\n",
    "url_real_prefix = 'https://www.patheos.com/blogs/'\n",
    "\n",
    "for post_url in tqdm(unique_subblog_list):\n",
    "    #print(post_url)\n",
    "    for blog_name in final_bname:\n",
    "        test_url = url_real_prefix + blog_name\n",
    "        #i = 2010\n",
    "        #while (i < 2020):\n",
    "        for y in year:\n",
    "            if post_url.startswith(test_url + \"/\" + str(y)):\n",
    "                final_real_post.append(post_url)\n",
    "            #i = i + 1\n",
    "#final_real_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_real_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_posts = list(set(final_real_post))\n",
    "len(individual_posts)\n",
    "\n",
    "comments1 = \"#disqus_thread\"\n",
    "\n",
    "list_without_disqus = []\n",
    "\n",
    "for word3 in individual_posts:\n",
    "    if not word3.endswith(comments1):\n",
    "        #individual_posts.remove(word3)\n",
    "        list_without_disqus.append(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(individual_posts)\n",
    "len(list_without_disqus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts_only = []\n",
    "\n",
    "for word4 in list_without_disqus:\n",
    "    count_list = word4.rsplit(\"/\")\n",
    "    count = len(count_list)\n",
    "    if (count > 8):\n",
    "        list_posts_only.append(word4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_posts_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped_urls = pd.DataFrame(list_posts_only)\n",
    "#df_new_urls.to_csv('patheos_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tnsnames_path = \"\"\n",
    "    server = \"PATHEOSDBAPEX\"\n",
    "    #df_scraped_urls = pd.DataFrame\n",
    "    environment = tns.parse_tnsnames(tnsnames_path, server)\n",
    "    print(environment)\n",
    "    database_user = \"no_input\" #input(\"Xnumber or Banner Username: \")\n",
    "    database_user = database_user.upper()\n",
    "    #banner_database = environment_select(input(\"Banner database: \"))\n",
    "    #environment_user = (\"Data base user: \")\n",
    "    environment_user = 'system'\n",
    "    environment_password = 'oracle' #getpass.getpass(environment_user + \" Password: \")\n",
    "    temp_list = pprocess.process_results(pcompare.access_compare_query(environment_user, environment_password, database_user, environment, df_scraped_urls))\n",
    "    temp_df = pscrape.full_scrape(temp_list, \"yes\")\n",
    "    pprocess.process_results(pinsert.access_insert_execute(environment_user, environment_password, database_user, environment, temp_df))\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "main()\n",
    "#df_test = main()\n",
    "\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_excel('patheos_posts_content.xlsx')\n",
    "df_results.to_csv('patheos_posts_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in invalid urls:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
